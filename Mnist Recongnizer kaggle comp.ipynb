{"cells":[{"metadata":{"_cell_guid":"654456b6-e648-0379-0d66-1cc97af6d00d","_uuid":"6b48ce0e361bdb67689dd2f254ecedd9ade1f5ff"},"cell_type":"markdown","source":"**Import all required libraries**\n==============================="},{"metadata":{"_cell_guid":"e5b02688-c589-5a89-e11c-837c6a99eb6e","_uuid":"f043e48097bfd98e41710142dd8aac41fa88a801","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout , Lambda, Flatten\nfrom keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"digit-recognizer\n\n","name":"stdout"}]},{"metadata":{"_cell_guid":"22a7fd70-ab61-432d-24cb-93e558414495","_uuid":"62fbd0fe9c338b7ac0b04e688c8ee7947e6170f7"},"cell_type":"markdown","source":"**Load Train and Test data**\n============================"},{"metadata":{"_cell_guid":"05226b08-226a-1a00-044d-a0e6b2101388","_uuid":"4eff577bcd43479a3b7e91180393cbad9fcfca33","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\nprint(train.shape)\ntrain.head()","execution_count":2,"outputs":[{"output_type":"stream","text":"(42000, 785)\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"2ec570a6-b41a-2139-5e0e-4941c4f0a9d0","_uuid":"67f0854ad0d812a1395130144a0adef9966fec88","trusted":true},"cell_type":"code","source":"test= pd.read_csv(\"../input/digit-recognizer/test.csv\")\nprint(test.shape)\ntest.head()","execution_count":3,"outputs":[{"output_type":"stream","text":"(28000, 784)\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 784 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"1ae10fe0-dde9-7659-f53d-1a1bd625cfb1","_uuid":"bdffbed77ce62da528c60e43f2b1bea9f57fcdbc","trusted":true},"cell_type":"code","source":"X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') \nX_test = test.values.astype('float32')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nX_test.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(28000, 28, 28, 1)"},"metadata":{}}]},{"metadata":{"_cell_guid":"250b1126-ce1d-6d3f-9736-2504f7a1e098","_uuid":"5e3e1e3574c3e019eadfd14e4dda41fd15b4de2a","trusted":true},"cell_type":"code","source":"#expand 1 more dimention as 1 for colour channel gray\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_train.shape","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(42000, 28, 28, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array([[[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       ...,\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]],\n\n\n       [[[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        ...,\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]],\n\n        [[0.],\n         [0.],\n         [0.],\n         ...,\n         [0.],\n         [0.],\n         [0.]]]], dtype=float32)"},"metadata":{}}]},{"metadata":{"_cell_guid":"e0f15f8a-ac08-540a-58db-dab989cc687c","_uuid":"4c96cf1c9cdc364ae3faff6b8c3c97aa7fa982d4","trusted":true},"cell_type":"code","source":"y_train","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"array([1, 0, 1, ..., 7, 6, 9], dtype=int32)"},"metadata":{}}]},{"metadata":{"_cell_guid":"c2c91588-5547-353a-7f92-39600027438e","_uuid":"f01a969286e62fa5ffe37031ed6d4aea947b59a8"},"cell_type":"markdown","source":"The output variable is an integer from 0 to 9. This is a **multiclass** classification problem."},{"metadata":{"_cell_guid":"1232c385-3cb2-56fd-4d1d-f027df7bc78e","_uuid":"185d620525e041eb61aabce19e8536614ab50870"},"cell_type":"markdown","source":"**Preprocessing the digit images**\n=================================="},{"metadata":{"_cell_guid":"6fcc1f9e-1586-e393-49ba-50c73564e0ed","_uuid":"b8847f48f7408c93ce795db16f30c1b7c6a8cf89"},"cell_type":"markdown","source":"**Feature Standardization**\n-------------------------------------\n\nIt is important preprocessing step.\n"},{"metadata":{"_cell_guid":"a3f837ef-0373-8d91-46e6-30992cf73166","_uuid":"528a370b381c91b73131a8c7a4217968278696c8","trusted":true},"cell_type":"code","source":"mean_pixels = X_train.mean().astype(np.float32)\nstd_pixels = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_pixels)/std_pixels","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"725c55fc-9742-a63c-9822-c67ab0c773ee","_uuid":"532d3f3bd26b0dfb42bc0c96e9710269234fae9b"},"cell_type":"markdown","source":"*One Hot encoding of labels.*\n-----------------------------\n"},{"metadata":{"_cell_guid":"c879f076-b3dd-6cb1-e2d9-2f404f2ed132","_uuid":"41bb3082e71111d73dd0432f9f60261f5be05e15","trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"10"},"metadata":{}}]},{"metadata":{"_cell_guid":"4d76fb04-57fc-e802-6d91-06ece552686b","_uuid":"429e528f5bf36152cd9e0b2acaa457525a202171"},"cell_type":"markdown","source":"Lets plot 10th label."},{"metadata":{"_cell_guid":"6a89dcdd-7b68-6ed1-2c39-b3a1edb3e7be","_uuid":"dc7ece2b7ee08767b664149d67d922d8c1d0bbb1"},"cell_type":"markdown","source":"**Designing Neural Network Architecture**\n========================================="},{"metadata":{"_cell_guid":"39107235-d87a-af4d-44fb-80c9c3aa0212","_uuid":"1070353d05490ccec23933c62f11cdfd2d7e5032","trusted":true},"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"a8b65f54-398b-267f-e31a-313210450f54","_uuid":"62606ecbb1d7e259850aebf8a8514e54263a2a06"},"cell_type":"markdown","source":"*Linear Model*\n--------------"},{"metadata":{"_cell_guid":"5dbe450c-845f-aaa2-dbde-21414a91d8c1","_uuid":"5f54b59d89cd4e43dd129d9b133950ba83b5cad8","trusted":true},"cell_type":"code","source":"from keras.models import  Sequential\nfrom keras.layers.core import  Lambda , Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"5c3f674f-f3fc-9614-f2d4-056c3e3ad633","_uuid":"ff25a88562237e84e44f20b38079f2b44a394d2c"},"cell_type":"markdown","source":"Lets create a simple model from Keras Sequential layer.\n\n1. Lambda layer performs simple arithmetic operations like sum, average, exponentiation etc.\n\n In 1st layer of the model we have to define input dimensions of our data.\n"},{"metadata":{"_cell_guid":"a2c27783-3cfa-e907-4749-1e340a513f26","_uuid":"fb79b4558335446a722542c8bc06288e96781423","trusted":true},"cell_type":"code","source":"model= Sequential()\nmodel.add(Lambda(standardize,input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nprint(\"input shape \",model.input_shape)\nprint(\"output shape \",model.output_shape)","execution_count":13,"outputs":[{"output_type":"stream","text":"input shape  (None, 28, 28, 1)\noutput shape  (None, 10)\n","name":"stdout"}]},{"metadata":{"_cell_guid":"260645fb-61b7-68e9-6826-047b97436c14","_uuid":"2dd7f371688dd2590de94a94814799654595e55d"},"cell_type":"markdown","source":"***Compile network***\n"},{"metadata":{"_cell_guid":"9d1d1af9-b2a8-e3b9-6eaf-100d08fe83aa","_uuid":"4bb75be10b9eec8bcdfe48665f639bf326a5f5fc","trusted":true},"cell_type":"code","source":"from keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(lr=0.001),\n loss='categorical_crossentropy',\n metrics=['accuracy'])","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Image generator <h3>"},{"metadata":{"_cell_guid":"db3b4be6-4f72-c6cc-65cd-b45978db2462","_uuid":"51f82558d87e95fa5c146b0469ab6c8b42e13bcf","trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"841a6f3b78b607e142f3e18d88bd7957202e4dcb"},"cell_type":"markdown","source":"## Cross Validation "},{"metadata":{"_cell_guid":"9071d720-da50-8530-e9f3-1f0c37aac7ff","_uuid":"0cff7e02b1ee8894b4ee9080b9268558aaa4e7c5","trusted":true},"cell_type":"code","source":"batch_size = 64\nfrom sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\nbatches = gen.flow(X_train, y_train, batch_size=batch_size)\nval_batches=gen.flow(X_val, y_val, batch_size=batch_size)","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"20e08e2a-a394-bb70-69f1-be0fdab4f9ab","_uuid":"6b23c282e2772b1ee482596131d6f1d3494c3bce","trusted":true},"cell_type":"code","source":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n//batch_size, epochs=3, \n                    validation_data=val_batches, validation_steps=val_batches.n//batch_size)","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n590/590 [==============================] - 3s 6ms/step - loss: 0.4504 - accuracy: 0.8664 - val_loss: 0.3864 - val_accuracy: 0.9014\nEpoch 2/3\n590/590 [==============================] - 3s 5ms/step - loss: 0.3047 - accuracy: 0.9131 - val_loss: 0.3388 - val_accuracy: 0.9132\nEpoch 3/3\n590/590 [==============================] - 3s 5ms/step - loss: 0.2877 - accuracy: 0.9190 - val_loss: 0.3759 - val_accuracy: 0.9168\n","name":"stdout"}]},{"metadata":{"_cell_guid":"9f344366-c372-0b04-b7e0-860778d4bfd3","_uuid":"6900e38c62028692b9f101b94730c527129675cc","trusted":true},"cell_type":"code","source":"history_dict = history.history\nhistory_dict.keys()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"},"metadata":{}}]},{"metadata":{"_cell_guid":"df40f5fc-586a-1fae-025e-ee508a8d9b71","_uuid":"c4b26ff79e0f186212266b60d03611ad58d0d5e3","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss_values, 'bo')\n# b+ is for \"blue crosses\"\nplt.plot(epochs, val_loss_values, 'b+')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.show()","execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"_uuid":"64ec304e056ec0c9e33fe94ea2315cbf65a7fbff"},"cell_type":"markdown","source":"## Fully Connected Model\n\nNeurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. \nAdding another Dense Layer to model."},{"metadata":{"_uuid":"9556f3de5bd370bcddc70a81910eb2104624e3a3","trusted":true},"cell_type":"code","source":"def get_fc_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"1901b6805f878ac6ed4efafbaf15bf003d505654","trusted":true},"cell_type":"code","source":"fc = get_fc_model()","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"5fb346c542c8920fac61ddc5df44b2136969a6e9","trusted":true},"cell_type":"code","source":"history=fc.fit_generator(generator=batches, steps_per_epoch=batches.n//batch_size, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n//batch_size)","execution_count":22,"outputs":[{"output_type":"stream","text":"Epoch 1/1\n590/590 [==============================] - 4s 6ms/step - loss: 0.4434 - accuracy: 0.8734 - val_loss: 0.5250 - val_accuracy: 0.9240\n","name":"stdout"}]},{"metadata":{"_uuid":"46b81b17854a98f2b380da694691502c1e583bfb"},"cell_type":"markdown","source":"## Convolutional Neural Network\n\n"},{"metadata":{"_uuid":"fd0ab0de6bdbf7addf7515c8d7b59d8d17fef8e7","trusted":true},"cell_type":"code","source":"from keras.layers import Convolution2D, MaxPooling2D\n\ndef get_cnn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Convolution2D(64,(3,3), activation='relu'),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(1e-4), loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"b5baeaed50c9f03c68900461555f4b7831a7e7c7","trusted":true},"cell_type":"code","source":"model= get_cnn_model()","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"a3d15eeead8b26c41b53d084dc111ae9e667a169","trusted":true},"cell_type":"code","source":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n//batch_size, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n//batch_size)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/1\n145/590 [======>.......................] - ETA: 7s - loss: 0.9443 - accuracy: 0.7491","name":"stdout"}]},{"metadata":{"_uuid":"e2891c7e434a2022ee182a0e9bd243a876532dcc"},"cell_type":"markdown","source":"## Data Augmentation\nIt is tehnique of showing slighly different or new images to neural network to avoid overfitting. And  to achieve better generalization.\nIn case you have very small dataset, you can use different kinds of data augmentation techniques to increase your data size. Neural networks perform better if you provide them more data.\n"},{"metadata":{"_uuid":"daa409b92678202cf7c751371b7ba17fb14aa2ac","trusted":true},"cell_type":"code","source":"gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n                               height_shift_range=0.08, zoom_range=0.08)\nval_gen = ImageDataGenerator()\nbatches = gen.flow(X_train, y_train, batch_size=32)\nval_batches = val_gen.flow(X_val, y_val, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"538f504c44e14d389c70b2f35b7225de61b9015d"},"cell_type":"markdown","source":"## Adding Batch Normalization + Dropout \n\nBN helps to fine tune hyperparameters more better and train really deep neural networks.\n\nDropout helps preventing overfitting"},{"metadata":{"_uuid":"8b72580fbb06f5f4f769c514cb0d7d2f15aa2c2f","trusted":true},"cell_type":"code","source":"from keras.layers.normalization import BatchNormalization\n\ndef get_bn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(pool_size=(2,2)),\n        Dropout(0.1),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(pool_size=(2,2)),\n        Dropout(0.2),\n        Flatten(),\n        BatchNormalization(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78e382d0b3de14312e762edc480b5d215be82269","trusted":true},"cell_type":"code","source":"model= get_bn_model()\nbatch_size=64\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n//batch_size, epochs=20, \n                    validation_data=val_batches, validation_steps=val_batches.n//batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e4b16516a57e152a911f6e7ba7f4d70ff204512"},"cell_type":"markdown","source":"## Submitting Predictions to Kaggle.\nMake sure you use full train dataset here to train model and predict on test set.\n"},{"metadata":{"_uuid":"0fc055b482971b36561aaf9421c8a9c53df2900b","trusted":true},"cell_type":"code","source":"gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n                               height_shift_range=0.08, zoom_range=0.08)\nbatches = gen.flow(X, y, batch_size=64)\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n//batch_size, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c2841d54-f3dd-1ee8-a30d-4457dec0a67a","_uuid":"4262c6bfb15ec96993e83bd2a2552eadf14fb33d","collapsed":true,"trusted":false},"cell_type":"code","source":"predictions = model.predict_classes(X_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"submissions=submissions.set_index('ImageId')\nsubmissions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\n# create a link to download the dataframe\ncreate_download_link(submissions)","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}